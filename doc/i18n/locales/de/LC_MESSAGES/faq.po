# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2000-2014 Bastian Kleineidam
# This file is distributed under the same license as the LinkChecker
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: LinkChecker \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-08-05 19:32+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../src/faq.rst:4
msgid "Frequently Asked Questions"
msgstr ""

#: ../../src/faq.rst:6
msgid ""
"**Q: LinkChecker produced an error, but my web page is okay with "
"Mozilla/IE/Opera/... Is this a bug in LinkChecker?**"
msgstr ""

#: ../../src/faq.rst:9
msgid ""
"A: Please check your web pages first. Are they really okay? Often the "
"major browsers are very forgiving and good at handling HTML of HTTP "
"errors, while LinkChecker complains in most cases of invalid content."
msgstr ""

#: ../../src/faq.rst:14
msgid ""
"Enable the :ref:`man/linkcheckerrc:HtmlSyntaxCheck` plugin, or check if "
"you are using a proxy which produces the error."
msgstr ""

#: ../../src/faq.rst:18
msgid "**Q: I still get an error, but the page is definitely okay.**"
msgstr ""

#: ../../src/faq.rst:20
msgid ""
"A: Some servers deny access of automated tools (also called robots) like "
"LinkChecker. This is not a bug in LinkChecker but rather a policy by the "
"webmaster running the website you are checking. Look in the "
"``/robots.txt`` file which follows the `robots.txt exclusion standard "
"<http://www.robotstxt.org/robotstxt.html>`_."
msgstr ""

#: ../../src/faq.rst:26
msgid ""
"For identification LinkChecker adds to each request a User-Agent header "
"like this::"
msgstr ""

#: ../../src/faq.rst:31 ../../src/faq.rst:91
msgid ""
"If you yourself are the webmaster, consider allowing LinkChecker to check"
" your web pages by adding the following to your robots.txt file::"
msgstr ""

#: ../../src/faq.rst:38
msgid "**Q: How can I tell LinkChecker which proxy to use?**"
msgstr ""

#: ../../src/faq.rst:40
msgid ""
"A: LinkChecker works automatically with proxies. In a Unix or Windows "
"environment, set the http_proxy, https_proxy, ftp_proxy environment "
"variables to a URL that identifies the proxy server before starting "
"LinkChecker. For example:"
msgstr ""

#: ../../src/faq.rst:51
msgid ""
"**Q: The link \"mailto:john@company.com?subject=Hello John\" is reported "
"as an error.**"
msgstr ""

#: ../../src/faq.rst:54
msgid ""
"A: You have to quote special characters (e.g. spaces) in the subject "
"field. The correct link should be \"mailto:...?subject=Hello%20John\" "
"Unfortunately browsers like IE and Netscape do not enforce this."
msgstr ""

#: ../../src/faq.rst:59
msgid "**Q: Has LinkChecker JavaScript support?**"
msgstr ""

#: ../../src/faq.rst:61
msgid ""
"A: No, it never will. If your page is only working with JS, it is better "
"to use a browser testing tool like `Selenium <http://seleniumhq.org/>`_."
msgstr ""

#: ../../src/faq.rst:65
msgid "**Q: Is the LinkCheckers cookie feature insecure?**"
msgstr ""

#: ../../src/faq.rst:67
msgid ""
"A: Potentially yes. This depends on what information you specify in the "
"cookie file. The cookie information will be sent to the specified hosts."
msgstr ""

#: ../../src/faq.rst:71
msgid ""
"Also, the following restrictions apply for cookies that LinkChecker "
"receives from the hosts it check:"
msgstr ""

#: ../../src/faq.rst:74
msgid ""
"Cookies will only be sent back to the originating server (i.e. no third "
"party cookies are allowed)."
msgstr ""

#: ../../src/faq.rst:76
msgid ""
"Cookies are only stored in memory. After LinkChecker finishes, they are "
"lost."
msgstr ""

#: ../../src/faq.rst:78
msgid "The cookie feature is disabled as default."
msgstr ""

#: ../../src/faq.rst:81
msgid ""
"**Q: LinkChecker retrieves a /robots.txt file for every site it checks. "
"What is that about?**"
msgstr ""

#: ../../src/faq.rst:84
msgid ""
"A: LinkChecker follows the `robots.txt exclusion standard "
"<http://www.robotstxt.org/robotstxt.html>`_. To avoid misuse of "
"LinkChecker, you cannot turn this feature off. See the `Web Robot pages "
"<http://www.robotstxt.org/robotstxt.html>`_ and the `Spidering report "
"<http://www.w3.org/Search/9605-Indexing-"
"Workshop/ReportOutcomes/Spidering.txt>`_ for more info."
msgstr ""

#: ../../src/faq.rst:98
msgid ""
"**Q: How do I print unreachable/dead documents of my website with "
"LinkChecker?**"
msgstr ""

#: ../../src/faq.rst:101
msgid ""
"A: No can do. This would require file system access to your web "
"repository and access to your web server configuration."
msgstr ""

#: ../../src/faq.rst:105
msgid "**Q: How do I check HTML/XML/CSS syntax with LinkChecker?**"
msgstr ""

#: ../../src/faq.rst:107
msgid ""
"A: Enable the :ref:`man/linkcheckerrc:HtmlSyntaxCheck` and "
":ref:`man/linkcheckerrc:CssSyntaxCheck` plugins."
msgstr ""

#: ../../src/faq.rst:111
msgid ""
"**Q: I want to have my own logging class. How can I use it in "
"LinkChecker?**"
msgstr ""

#: ../../src/faq.rst:113
msgid ""
"A: A Python API lets you define new logging classes. Define your own "
"logging class as a subclass of *_Logger* or any other logging class in "
"the *log* module. Then call the *add_logger* function in "
"*Config.Configuration* to register your new Logger. After this append a "
"new Logging instance to the fileoutput."
msgstr ""

